{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "0320a026",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "0320a026",
        "outputId": "6b9bc7ed-c7c6-4dee-ddcf-35429165dbc4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "id": "4b27b405",
      "metadata": {},
      "outputs": [],
      "source": [
        "def replace_ampersand(df_in):\n",
        "    \"\"\"\n",
        "    Replaces all ampersand (&) characters in the 'text' column with the word 'and'.\n",
        "    This is applied to the original text before other cleaning steps.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Applying Rule: Replace Ampersands (& -> 'and') ---\")\n",
        "    df_out = df_in.copy()\n",
        "    \n",
        "    # Use .str.replace() on the 'text' column. We add spaces around 'and' for proper formatting.\n",
        "    # We also check if the column exists first.\n",
        "    if 'text' in df_out.columns:\n",
        "        # Count how many rows are affected for reporting\n",
        "        rows_affected = df_out['text'].str.contains('&', na=False).sum()\n",
        "        df_out['text'] = df_out['text'].str.replace('&', ' and ', regex=False)\n",
        "        print(f\"➡️ Found and replaced ampersands in {rows_affected} sentences.\")\n",
        "    else:\n",
        "        print(\"⚠️ 'text' column not found.\")\n",
        "        \n",
        "    return df_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "34980f13",
      "metadata": {
        "id": "34980f13"
      },
      "outputs": [],
      "source": [
        "def preprocess_text_column(df_in):\n",
        "    \"\"\"\n",
        "    Applies universal preprocessing to the text:\n",
        "    1. Converts all text to lowercase.\n",
        "    2. Replaces all punctuation with a single space.\n",
        "    3. Collapses any multiple spaces into a single space.\n",
        "    Returns the DataFrame with a new 'cleaned_text' column.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Applying Universal Preprocessing (v2) ---\")\n",
        "    df_out = df_in.copy()\n",
        "\n",
        "    # Ensure text column is string and convert to lowercase\n",
        "    text_series = df_out['text'].astype(str).str.lower()\n",
        "\n",
        "    # --- CHANGE 1: Replace punctuation with a space ---\n",
        "    # Create a translation table that maps each punctuation character to a space\n",
        "    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
        "    text_series = text_series.str.translate(translator)\n",
        "\n",
        "    # --- CHANGE 2: Collapse multiple spaces into one ---\n",
        "    # Use a regular expression to replace one or more whitespace characters with a single space\n",
        "    # and strip any leading/trailing spaces.\n",
        "    text_series = text_series.str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "\n",
        "    df_out['cleaned_text'] = text_series\n",
        "\n",
        "    print(\"✅ Text converted to lowercase, punctuation replaced, and spaces normalized.\")\n",
        "    return df_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "id": "d2640ee3",
      "metadata": {
        "id": "d2640ee3"
      },
      "outputs": [],
      "source": [
        "def remove_exact_duplicates(df_in):\n",
        "    \"\"\"\n",
        "    Removes rows where the 'cleaned_text' is an exact duplicate of a previous one.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Applying Rule: Remove Exact Duplicates ---\")\n",
        "    initial_rows = len(df_in)\n",
        "\n",
        "    # Drop duplicates based on the 'cleaned_text' column, keeping the first instance\n",
        "    df_out = df_in.drop_duplicates(subset=['cleaned_text'], keep='first').copy()\n",
        "\n",
        "    final_rows = len(df_out)\n",
        "    print(f\"➡️ Sentences removed: {initial_rows - final_rows}\")\n",
        "    print(f\"➡️ Sentences remaining: {final_rows}\")\n",
        "    return df_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "e733f85e",
      "metadata": {
        "id": "e733f85e"
      },
      "outputs": [],
      "source": [
        "def remove_non_alpha_sentences(df_in):\n",
        "    \"\"\"\n",
        "    Removes any sentence that contains characters other than lowercase\n",
        "    letters and spaces in its 'cleaned_text'.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Applying Rule: Remove Sentences with Non-Alphabetic Characters ---\")\n",
        "    initial_rows = len(df_in)\n",
        "\n",
        "    def contains_only_alpha_and_space(text):\n",
        "        # The regex pattern '[^a-z\\s]' matches any character that is NOT a-z or a space.\n",
        "        # If re.search finds such a character, the sentence is invalid.\n",
        "        if re.search(r'[^a-z\\s]', text):\n",
        "            return False # Contains invalid characters\n",
        "        return True # All characters are valid\n",
        "\n",
        "    mask = df_in['cleaned_text'].apply(contains_only_alpha_and_space)\n",
        "    df_out = df_in[mask].copy()\n",
        "    \n",
        "    final_rows = len(df_out)\n",
        "    print(f\"➡️ Sentences removed: {initial_rows - final_rows}\")\n",
        "    print(f\"➡️ Sentences remaining: {final_rows}\")\n",
        "    return df_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "9569e9ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_by_character_length(df_in, min_length=4, max_length=120):\n",
        "    \"\"\"\n",
        "    Removes rows where the 'cleaned_text' character length is outside the\n",
        "    specified min and max range.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Applying Rule: Filter by Character Length (between {min_length} and {max_length}) ---\")\n",
        "    initial_rows = len(df_in)\n",
        "\n",
        "    # --- THIS IS THE MODIFIED PART ---\n",
        "    # Create a boolean mask to keep rows where the length is within the range\n",
        "    mask = (df_in['cleaned_text'].str.len() >= min_length) & (df_in['cleaned_text'].str.len() <= max_length)\n",
        "    df_out = df_in[mask].copy()\n",
        "    # ---------------------------------\n",
        "\n",
        "    final_rows = len(df_out)\n",
        "    print(f\"➡️ Sentences removed: {initial_rows - final_rows}\")\n",
        "    print(f\"➡️ Sentences remaining: {final_rows}\")\n",
        "    return df_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "a496151b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_by_word_count(df_in, min_words=3):\n",
        "    \"\"\"\n",
        "    Removes sentences that have fewer than the minimum number of words.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Applying Rule: Filter by Word Count (>= {min_words} words) ---\")\n",
        "    initial_rows = len(df_in)\n",
        "    \n",
        "    # Calculate word count for each sentence in the 'cleaned_text'\n",
        "    word_counts = df_in['cleaned_text'].str.split().str.len()\n",
        "    \n",
        "    # Keep rows where the word count is greater than or equal to the minimum\n",
        "    df_out = df_in[word_counts >= min_words].copy()\n",
        "    \n",
        "    final_rows = len(df_out)\n",
        "    print(f\"➡️ Sentences removed: {initial_rows - final_rows}\")\n",
        "    print(f\"➡️ Sentences remaining: {final_rows}\")\n",
        "    return df_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "id": "c9b4c8dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_high_repetition_sentences(df_in, threshold=0.7):\n",
        "    \"\"\"\n",
        "    Removes sentences that are overly repetitive based on a calculated ratio.\n",
        "    The ratio is the frequency of the most common word divided by the total number of words.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Applying Rule: Remove Sentences with Repetition Ratio > {threshold} ---\")\n",
        "    initial_rows = len(df_in)\n",
        "\n",
        "    def calculate_repeat_ratio(text):\n",
        "        \"\"\"Calculates the repetition ratio for a single sentence.\"\"\"\n",
        "        words = text.split()\n",
        "        total_words = len(words)\n",
        "        \n",
        "        # Avoid division by zero for empty or single-word sentences\n",
        "        if total_words <= 1:\n",
        "            return 0.0\n",
        "            \n",
        "        # Count the occurrences of each word\n",
        "        word_counts = Counter(words)\n",
        "        \n",
        "        # Find the count of the most common word\n",
        "        most_common_count = word_counts.most_common(1)[0][1]\n",
        "        \n",
        "        # Calculate the ratio\n",
        "        return most_common_count / total_words\n",
        "\n",
        "    # Calculate the ratio for each sentence\n",
        "    df_in['repeat_ratio'] = df_in['cleaned_text'].apply(calculate_repeat_ratio)\n",
        "    \n",
        "    # Create a mask to keep sentences below or equal to the threshold\n",
        "    mask = df_in['repeat_ratio'] <= threshold\n",
        "    df_out = df_in[mask].copy()\n",
        "    \n",
        "    # We can drop the temporary ratio column from the final output\n",
        "    df_out.drop(columns=['repeat_ratio'], inplace=True)\n",
        "    \n",
        "    final_rows = len(df_out)\n",
        "    print(f\"➡️ Sentences removed: {initial_rows - final_rows}\")\n",
        "    print(f\"➡️ Sentences remaining: {final_rows}\")\n",
        "    return df_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "id": "6862570c",
      "metadata": {
        "id": "6862570c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Successfully loaded the dataset.\n",
            "Initial number of sentences: 127237\n"
          ]
        }
      ],
      "source": [
        "# --- Load the Dataset ---\n",
        "try:\n",
        "    df = pd.read_csv('iSign_v1.1.csv')\n",
        "    original_rows = len(df)\n",
        "    print(f\"✅ Successfully loaded the dataset.\")\n",
        "    print(f\"Initial number of sentences: {original_rows}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"❌ Error: 'iSign_v1.1.csv' not found. Please make sure the file is in the correct directory.\")\n",
        "    df = None # Set df to None if file is not found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "id": "02c27050",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Applying Rule: Replace Ampersands (& -> 'and') ---\n",
            "➡️ Found and replaced ampersands in 2120 sentences.\n"
          ]
        }
      ],
      "source": [
        "df_processed=replace_ampersand(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "135aa1e9",
      "metadata": {
        "id": "135aa1e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Applying Universal Preprocessing (v2) ---\n",
            "✅ Text converted to lowercase, punctuation replaced, and spaces normalized.\n"
          ]
        }
      ],
      "source": [
        "df_processed = preprocess_text_column(df_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "3352b184",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Applying Rule: Filter by Character Length (between 4 and 120) ---\n",
            "➡️ Sentences removed: 4241\n",
            "➡️ Sentences remaining: 122996\n"
          ]
        }
      ],
      "source": [
        "df_processed = filter_by_character_length(df_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "id": "fb61100a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Applying Rule: Filter by Word Count (>= 3 words) ---\n",
            "➡️ Sentences removed: 5998\n",
            "➡️ Sentences remaining: 116998\n"
          ]
        }
      ],
      "source": [
        "df_processed = filter_by_word_count(df_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "b7b9d5f9",
      "metadata": {
        "id": "b7b9d5f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Applying Rule: Remove Exact Duplicates ---\n",
            "➡️ Sentences removed: 2348\n",
            "➡️ Sentences remaining: 114650\n"
          ]
        }
      ],
      "source": [
        "df_processed = remove_exact_duplicates(df_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "fe734994",
      "metadata": {
        "id": "fe734994"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Applying Rule: Remove Sentences with Non-Alphabetic Characters ---\n",
            "➡️ Sentences removed: 25484\n",
            "➡️ Sentences remaining: 89166\n"
          ]
        }
      ],
      "source": [
        "df_processed = remove_non_alpha_sentences(df_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "0010b21a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Applying Rule: Remove Sentences with Repetition Ratio > 0.7 ---\n",
            "➡️ Sentences removed: 32\n",
            "➡️ Sentences remaining: 89134\n"
          ]
        }
      ],
      "source": [
        "df_processed=remove_high_repetition_sentences(df_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "OcVpySDkRwgs",
      "metadata": {
        "id": "OcVpySDkRwgs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "--- ✅ Filtering Complete ---\n",
            "Total sentences removed in this step: 38103\n",
            "Final number of sentences after this step: 89134\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\\n--- ✅ Filtering Complete ---\")\n",
        "print(f\"Total sentences removed in this step: {len(df) - len(df_processed)}\")\n",
        "print(f\"Final number of sentences after this step: {len(df_processed)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "fcb4e93a",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_processed.to_csv('cleaned_data.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
